Memory Management
-------------

* 논리적 주소
  * 프로세스마다 독립적으로 가지는 주소 공간
  * 0번지부터 시작함
  * cpu는 논리적 주소를 통해 데이터를 읽는다.
* 물리적 주소
  * 실제 메모리에 올라가는 주소 공간
  * 일반적으로 낮은 주소 영역(0번지에 가까운)에는 os가 올라가고 높은 주소 영역에는 사용자 프로세스가 올라감
* 주소 바인딩
  * Symbol address(프로그래머가 작성한 변수 등) -> Logical address(컴파일을 통해 논리적 주소 변환) -> Physical address(물리적 주소)
  * 바인딩의 분류
    * Compile time binding
      * 프로그램을 컴파일 할 때 물리적 주소를 결정하는 방식
      * 변경이 불가능한 절대주소(Absolute address)로 배정
      * 물리적 메모리 주소를 변경하고 싶다면 재컴파일 해야함
      * 메모리의 공간이 부족했던 과거에 많이 사용했지만 현대에는 거의 사용하지 않음
    * Load time binding
      * 프로그램을 시작할 때 물리적 주소를 결정하는 방식
      * Loder를 통해 물리적 주소가 결졍되며 프로그램이 종료될 때 까지 주소 고정
      * 컴파일러가 재배치 가능 코드를 생성한 경우에만 가능
    * Runtime binding(Execution time binding)
      * 프로그램 실행중에도 물리적 주소를 변경할 수 있는 방식
      * 논리적 주소를 물리적 주소로 매핑하는 하드웨어 장치인 MMU를 사용
      * MMU(Memory management uint)
        * relocation 레지스터와 limit 레지스터 2개를 이용해 주소를 변환
        * limit 레지스터는 프로그램의 크기를 넘어서는 요청에는 trap을 발생시켜 os에 제어권을 넘김 
        * relocation 레지스터는 물리적 주소의 시작위치에 논리적 주소를 더하여 요청된 주소값으로 변환
        * cpu는 물리적 주소를 알 필요가 없음
* 메모리 용어
  * Dynamic Loading(동적로딩)
    * 프로세스 전체를 메모리에 올리지 않고 필요한 루틴이 있을때 그 루틴을 메모리에 올림
    * 오류처리 루틴처럼 자주 사용되지 않지만 코드의 양이 많을때 유용함
    * os의 도움을 받지 않고 프로그램 자체에서 구현할 수 있음
    * os의 라이브러리의 지원을 받아 구현할 수 있음
  * Dynamic Linking(동적연결)
    * 연결이란 프로그래머가 작성한 코드를 컴파일 한 목적 파일과 이미 컴파일된 라이브러리 파일등을 묶어 하나의 실행 파일로 생성하는 과정
    * 동적 연결은 컴파일을 통한 목적 파일과 라이브러리 파일의 연결을 프로그램 실행 시점까지 지연하는 기법
    * 정적 연결
      * 라이브러리가 프로그램 실행 파일 코드에 포함됨
      * 실행파일의 크기가 커짐
      * 동일한 라이브러리를 각 프로세스 메모리에 올리므로 메모리 낭비가 심함
    * 동적 연결
      * 실행 파일에 코드가 포함되지 않으며 프로그램이 실행되고 라이브러리를 호출할 때 연결됨
      * 라이브러리 호출 부분에 루틴의 위치를 찾기위한 stub이라는 작은 코드를 만듬
      * 라이브러리가 메모리에 있다면 그 주소로 가고 없다면 디스크에서 읽어옴
      * os의 도움이 필요
  * Overlays
    * 메모리에 프로새스의 부분 중 실제 필요한 정보만을 올리는 기법
    * 프로세스의 크기가 메모리보다 클 떄 유용함
    * 물리적 메모리 크기가 부족하여 하나의 프로세스를 메모리에 전부 올릴수 없을때 현재 필요한 부분만 먼저 올려 실행시키고 실행히 끝나 반환되면 나머지 부분을 올려 실행하는 기법
    * 구현하기 복잡하고 어려움
  * Swapping
    * 메모리의 올라온 프로세스를 디스크의 backing store(swap area)로 쫒아내는것
    * 디스크에서 메모리로 올리는 작업을 swap in, 메모리에서 디스크로 내리는 작업을 swap out이라 함
    * swap 과정
      * 중기 스케줄러가 swap out 할 프로세스를 정함
      * 우선 순위가 높은 프로세스를 swap in 함
      * 우선 순위가 낮은 프로세스를 swap out 함
    * 컴파일 타임 바인딩이나 로드 타임 바인딩이 사용되고 있다면 swap out 되었다 swap in 된다면 원래 메모리 위치로 가야해서 그다지 효율적이지 않음
    * 런타임 바인딩이 사용되고 있다면 자유롭게 빈 메모리 공간에 올릴수 있으므로 효율적임
    * swap time은 디스크의 탐색 시간이나 회전 지연 시간 보다는 디스크에서 데이터를 읽고 전송하는 transfer time이 대부분임
* 사용자 프로세스의 할당 방법
  * 연속 할당
    * 각각의 프로세스가 메모리 공간에 연속적으로 배치되도록 하는것
    * 고정 분할 방식과 가변 분할 방식이 있음
    * 고정 분할 방식
      * 메모리를 정해진 개수에 맞춰 파티션으로 나누고 각 파티션마다 프로세스를 배치함
      * 동시에 메모리에 올릴수 있는 프로세스의 수와 크키가 고정되어 있어 효율적이지 못함
      * 외부조각과 내부조각이 발생할 수 있음
      * 외부 조각 : 프로세스의 크기보다 파티션이 작아 프로세스를 배치하지 못하여 생기는 공간
      * 내부 조각 : 프로세스의 크기보다 파티션이 커 프로세르를 배치하고도 남는 공간
    * 가변 분할 방식
      * 메모리에 배치되는 프로세스의 크기에 따라 파티션의 개수, 크기가 동적으로 변하는 방식
      * 미리 메모리 영역을 나누지 않음
      * 프로세스가 실행될 때마다 메모리에 올리므로 내부조각이 발생하지 않음
      * 하지만 프로세스의 실행이 끝나고 빈 공간(Hole)에 다른 프로세스가 배치된다면 외부 조각이 발생할 수 있음
      * Hole
        * 가용 공간이지만 프로세스의 크기와 딱 맞지 않아 발생하는 공간으로 메모리 여러 부분에서 존재할 수 있음
        * 프로세스를 배치할 때 Hole중에 하나 선택하여 배치해야 함
        * Hole를 배정하는 방식
          * First fit
            * 프로세스의 크기보다 큰 hole중 처음으로 찾는 hole에 배치
          * Best fit
            * 프로세스의 크기보다 큰 hole 중 가장 작은 hole을 배치
            * hole들이 정렬되어 있지 않다면 모든 hole을 탐색해야 함
            * 많은 수의 아주 작은 hole이 생성됨
          * Worst fit
            * 가장 큰 hole에 배치함
            * 모든 hole을 탐색해야 함
            * 다른 방식에 비해 아주 큰 hole들이 생성됨
          * First fit과 Best fit이 Worst fit 보다 빠른 속도와 공간 효울성이 높음
      * Compaction
        * 외부 조각 문제를 해결하는 방법
        * 사용중인 메모리와 빈 공간을 양쪽에 몰아서 배치하여 큰 가용 공간을 만드는 것
        * 많은 비용이 발생함
        * 최소한의 메모리 이동으로 압축하는 방법은 매우 복잡함
        * 실행중 동적으로 메모리 재배치가 가능한 런타임 바인딩 방식에서만 가능함
    * 불연속 할당
      * Paging
        * 프로세스의 주소 공간을 동일한 페이지 단위로 나누어 물리적 메모리에 배치하는 방식
        * 프로세스 전체를 메모리에 올리지 않고 일부는 메모리에 올리고 일부는 backing store에 두는 방식도 가능
        * 물리적 메모리를 페이지와 같은 동일한 프레임으로 미리 나누어 둠
        * 외부 조각이 발생하지 않고 동적 메모리 할당 문제도 고려할 필요가 없음
        * 페이지 테이블을 사용하여 논리적 주소를 물리적 주소로 변환하는 작업이 필요함
        * 프로세스의 크기가 항상 페이지 크기의 배수가 되는것은 아니므로 프로세스의 주소 공간 중 제일 마지막에 위치한 페이지에는 내부조각이 발생할 수 있음
        * 논리적 메모리는 페이지 단위로 분할, 물리적 메모리는 프레임 단위로 분할 이를 매칭하기 위해 페이지 테이블을 사용
        * 페이징 테이블을 이용한 주소 변환
          * 논리적 주소를 페이지 번호와 오프셋으로 나눈다.
          * 페이지 번호는 페이지 테이블의 인덱스 번호로 사용되고 그 인덱스에는 물리적 메모리의 시작 주소가 들어있다.
          * 특정 프로세스의 p번째 페이지의 물리적 시작 위치를 알고 싶다면 페이지 테이블의 p번째 항목을 찾아보면 된다.
          * 페이지 오프셋과 논리적 주소를 더하면 논리적 주소에 대응하는 물리적 주소를 알 수 있다.
        * 페이지 테이블의 구현
          * 페이지 테이블은 페이징 기법에서 주소 변환을 하기 위한 자료 구조로 물리적 메모리인 Main Memory에 상주한다.
          * 페이징 기법에서 2개의 레지스터
            * 페이지 테이블 기준 레지스터 : 메모리 내에서 페이지 테이블의 시작 위치를 가리킴
            * 페이지 테이블 길이 레지스터 : 페이지 테이블 크기를 보관함
          * 페이징 기법은 2번의 메모리 접근이 필요하다.
            * 주소 변환을 위해 페이지 테이블 접근 -> 변환된 주소에서 실제 데이터 접근
          * 메모리 접근 속도를 향상하기 위해 TLB(Translation Lock-aside Buffer)라고 불리는 고속 주소 변환용 하드웨어를 사용한다.
        * TLB
          * TLB는 자주 참조되는 페이지에 대한 주소 변환 정보만을 가진다.
          * 요청된 페이지 번호가 TLB에 존재한다면 바로 프레임 번호를 알수 있다.
          * 만약 TLB에 없다면 페이지 테이블에 접근하여 프레임 번호를 알아내야 한다.
          * TLB에 특정 페이지 번호가 있는지 탐색하는것은 시간이 오래 걸리기 때문에 병렬 탐색이 가능한 레지스터를 사용한다.
          * TLB는 context switch이 일어나면 내용이 전부 지워진다.
        * 계층적 페이징
          * 현대의 컴퓨터는 주소 공간이 큰 프로그램을 지원한다.
          * 32bit 주소 체계를 사용하는 컴퓨터라면 4GB 주소 공간을 갖는 프로그램을 지원한다.
          * 페이지 사이즈가 4KB라면 한 프로세스당 페이지 테이블을 위해 1MB 크기의 페이지 테이블 메모리 공간이 필요하다.
          * 그러나 대부분 프로그램은 4GB중 일부분만을 사용하므로 페이지 테이블의 공간이 낭비된다.
          * 2단계 페이징 기법
            * 외부 페이지 테이블과 내부 페이지 테이블, 2개의 페이지 테이블을 만들어 사용한다.
            * 사용하지 않는 주소 공간에 대해서는 외부 페이지 테이블의 항목을 Null로 설정하여 내부 페이지 테이블을 만들지 않는다.
            * 페이지 테이블에 사용되는 메모리를 절약하지만 전체적인 페이지 테이블 숫자가 증가하므로 시간이 오래 걸린다.
      * Segmentation
      * Paged segmentation